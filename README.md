# EAI_Paper_Review

## `CNN Architecture`
* [ImageNet Classification with Deep Convolutional Neural Networks](https://velog.io/@hseop/ImageNet-Classification-with-Deep-Convolutional-Neural-Networks)
* [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION](https://velog.io/@hseop/VERY-DEEP-CONVOLUTIONAL-NETWORKS-FOR-LARGE-SCALE-IMAGE-RECOGNITION-VGGNet)
* [Network In Network](https://velog.io/@hseop/Network-In-Network)
* [Going deeper with convolutions](https://velog.io/@hseop/GoogleNet-Going-deeper-with-convolutions)
* [Batch Normalization : Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://velog.io/@hseop/Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift)
* [Deep Residual Learning for Image Recognition](https://velog.io/@hseop/ResNet-Deep-Residual-Learning-for-Image-Recognition)
* [MobileNetV2: Inverted Residuals and Linear Bottlenecks, Sandler](https://velog.io/@hseop/MobileNetV2-Inverted-Residuals-and-Linear-Bottlenecks-Sandler)


## `Transformer Architecture`
* [Attention Is All You Need](https://velog.io/@hseop/Attention-Is-All-You-Need)
* [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://velog.io/@hseop/ViT-An-Image-is-Worth-16x16-Words-Transformers-for-Image-Recognition-at-Scale)
* [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://velog.io/@hseop/SwinT-Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows)
* 

## `Efficient`
* [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://velog.io/@hseop/Deep-Compression-Compressing-Deep-Neural-Networks-with-Pruning-Trained-Quantization-and-Huffman-Coding)
* [Pruning Filters for Efficient Convnets](https://velog.io/@hseop/PRUNING-FILTERS-FOR-EFFICIENT-CONVNETS)
* [Adaptive Depth Networks with Skippable Sub-Paths](https://velog.io/@hseop/Adaptive-Depth-Networks-with-Skippable-Sub-Paths)


## `Hybrid Arhictecture (CNN + Transformer)`
* [CvT: Introducing Convolutions to Vision Transformers](https://velog.io/@hseop/CvT-Introducing-Convolutions-to-Vision-Transformers)
* [Training data-efficient image transformers & distillation through attention](https://velog.io/@hseop/Simple-Review-DeiT-Training-data-efficient-image-transformers-distillation-through-attention)
* [LeViT: a Vision Transformer in ConvNetâ€™s Clothing for Faster Inference](https://velog.io/@hseop/LeViT-a-Vision-Transformer-in-ConvNets-Clothing-for-Faster-Inference)
* [CoAtNet: Marrying Convolution and Attention for All Data Sizes](https://velog.io/@hseop/CoAtNet-Marrying-Convolution-and-Attention-for-All-Data-Sizes)


## `Detection` 
* [R-CNN](https://velog.io/@hseop/Simple-Review-Region-based-Convolutional-Networks-for-Accurate-Object-Detection-and-Segmentation)
* [Fast R-CNN](https://velog.io/@hseop/Fast-R-CNN)
* [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://velog.io/@hseop/Faster-R-CNN-Towards-Real-Time-Object-Detection-with-Region-Proposal-Networks)
* [You Only Look Once : Unified, Real-Time Object Detection](https://velog.io/@hseop/YOLO-You-Only-Look-Once-Unified-Real-Time-Object-Detection)
* [YOLO9000: Better, Faster, Stronger](https://velog.io/@hseop/YOLO9000-YOLOv2-YOLO9000-Better-Faster-Stronger)
* [YOLOv3: An Incremental Improvement](https://velog.io/@hseop/Simple-Review-YOLOv3-YOLOv3-An-Incremental-Improvement)
* [Feature Pyramid Network for Object Detection](https://velog.io/@hseop/FPN-Feature-Pyramid-Network-for-Object-Detection)
* [YOLOv4: Optimal Speed and Accuracy of Object Detection](https://velog.io/@hseop/YOLOv4-YOLOv4-Optimal-Speed-and-Accuracy-of-Object-Detection)
* [EfficientDet: Scalable and Efficient Object Detection](https://velog.io/@hseop/Simple-Review-EfficientDet-Scalable-and-Efficient-Object-Detection#4-efficientdet)
* [Focal Loss for Dense Object Detection](https://velog.io/@hseop/RetinaNet-Focal-Loss-for-Dense-Object-Detection)
* [End-to-End Object Detection with Transformers](https://velog.io/@hseop/DETR-End-to-End-Object-Detection-with-Transformers)
* [Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://velog.io/@hseop/Simple-ReviewDeformable-DETR-Deformable-DETR-Deformable-Transformers-for-End-to-End-Object-Detection)
* [DETRs Beat YOLOs on Real-time Object Detection](https://velog.io/@hseop/DETRs-Beat-YOLOs-on-Real-time-Object-Detection)
* [DETR > Deformable DETR > RT-DETR](https://velog.io/@hseop/DETR-Deformable-DETR-RT-DETR)
* [RTMDet: An Empirical Study of Designing Real-Time Object Detectors](https://velog.io/@hseop/RTMDet-An-Empirical-Study-of-Designing-Real-Time-Object-Detectors)
* [YOLOv10: Real-Time End-to-End Object Detection](https://velog.io/@hseop/YOLOv10-Real-Time-End-to-End-Object-Detection)